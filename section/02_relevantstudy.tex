\chapter{先行研究}
\label{chap:relevantstudy}

本章では不完全情報ゲームの関連研究について述べる。麻雀の研究としては以下の研究が報告されている。

\section{人間プレイヤーの牌譜から学習する手法を用いた研究}
人間プレイヤーの牌譜を教師信号とした麻雀評価関数の機械学習の報告がいくつかなされている。
北川らは評価関数に 3 層ニューラルネットワークを用い た教師あり学習を用いることで麻雀 AI のパラメータ調整 を行った。\cite{kitakawa}牌譜と AI の一致率はツモ局面において約56％, 鳴き局面において約89％,東風荘で得られたレートは 1318 であった[6].
三木らは木カーネルを用いた非線形 SVM によって手牌 の分類を学習した.ツモ局面における人間プレイヤーとの 一致率は 51％であった\cite{miki}。
しかし、いずれの方法も人間の平均プレイヤの実力に達していない。

水上ら\cite{bakuuti}１人麻雀プレイ ヤの学習に牌譜との一致を目指した平均化パーセプトロンを用いた。麻雀の特徴量は非常に膨大なため、この方法が採用された。学習に使った教師信号は、麻 雀サイト天鳳 \cite{tenhou} において鳳凰卓でプレイすることができ るプレイヤの試合データである。鳳凰卓でプレ イできるのは全プレイヤの中でも上位 0.1％程度であり牌
譜の質は高いと考えられる。この研究では、１人麻雀プレイヤの和了率が平均プレイヤを上回り、鳳凰卓でプレイできるプレイヤの和了率に近いレベルになった。
しかし、１人麻雀プレイヤの学習を行う際に、４人麻雀の牌譜を使っていることで、４人麻雀独特の打ち方を排除できない問題や、上級者が認知できない最適解を求められない問題があった。

% 1 人麻雀プレイヤは「上級者」に近いレベルになってい ることがわかる。先行研究が平均プレイヤにも大きく届か なかったことを考えると、1 人麻雀ではあるが大きく上達 している。この論文では平均プレイヤは上位 50% ほどの プレイヤであり、「上級者」は本論文の第 1 著者であり、
% 上記の1人麻雀の評価関数の学習には多くの教師データ
% が必要になる。教師データとしてはインターネット麻雀
% サイト天鳳 [8] の鳳凰卓の牌譜を用いた *1 。鳳凰卓でプレ イできるのは全プレイヤの中でも上位 0.1% 程度であり牌
% 譜の質は高いと考えられる。ただし、この牌譜をそのまま 使ったのではデータに 4 人麻雀に特有と考えられる手が局 面があり、1人麻雀の教師データとしてふさわしくない。 そこで、ある1局において初めてリーチをしたプレイヤが リーチをかけるまでの局面についてのみ教師データとし た。最終的な教師データの数は約 170 万局面となった。

\section{麻雀についてモンテカルロ法を応用した研究}
% モンテカルロ木探索を用いた方法がある。この手法では麻雀のゲーム木の探索を正確に行うのは難しいため、相手の手牌や行動をランダムでシミュレートするモンテカルロ木探索を用いた。この方法では麻雀の知識をほとんど使わないに
% もかかわらず、シャンテン数を下げるように打つという簡
% 単なルールを書いたプレイヤよりも成績が上回る結果と
% なった。しかし挙動として相手はシミュレート時にほとん
% ど和了できないことから、鳴きを入れて形式聴牌を取りに
% 行く行動をとるため、人間が行うプレイとは大きく異なっ
% ていた。いずれの関連研究も平均レベルのプレイヤに達し
% ていない。

\subsection{UCB1}
UCB1 はUCB1 値が最大となるノードに対してプレイアウトを行い, その結果により UCB1 値 を更新するという手順を一定回数繰り返し, 最も平均報酬 が高い選択肢を選ぶアルゴリズムである。
UCB１値は、j は子ノード j の平均報酬, α は定数, n は親ノードの探索回数, nj は子ノード j とした時、
$UCB=xj+α √2logn　nj (1)$ 
で表される。
x 式 (1) 右辺の第 1 項は平均報酬を, 第 2 項は信頼度を示している. 信頼度はそのノードのプレイアウト回数が少ないと大きく, 多いと小さくなる. UCB1 値を用いることで UCB1 ではよ り有望そうな手に対して多くのシミュレーションを行う事 ができる. UCB1 は各局面ごとにこの手順を実行するが, 各局面を完全に異なる局面として扱うため, 他の局面の探 索において得られた情報を共有することができないという 欠点を持つ. この欠点を補うアルゴリズムとして期待され ているのが LinUCB である.
\subsection{Lin UCB}
LinUCB [5] は, UCB を局面を特徴で表すことができる ように拡張したものであり, 牌譜の局面からの教師あり学 習や異なる探索の結果の共有ができる手法である。
% LinUCB はプレイアウトを行う子ノードを選択する評価値の計算に, 重みベクトル, 特徴ベクトル, 特徴の頻度を表す相関行列を 用いる. 計算により求めた評価値が最大となる子ノードに 対してプレイアウトを行い, 共通で保持する重みベクトル を更新する. 重みベクトルは, 選択したノードの特徴ベクト ルの各項にプレイアウト結果の報酬を乗じた値を, 重みベ クトルの対応する項に足し込んで更新する. この更新によ り, 高い報酬を得た特徴は大きな重みを, 低い報酬の特徴は 小さな重みを持つようになるため, 当該ノードだけでなく, 同様の特徴を持つ他のノードの評価値も更新される. これ により異なる局面で得られた情報を共有し, 利用すること ができる. また LinUCB は探索を行った結果を重みベクト ルとして記録しておくことで, 事前学習の結果を用いる探 索として利用することも可能である.
% LinUCB のアルゴリズムを Algorithm 1 に示す. ただし xt,at はプレイアウト回数が t 回目の時の選択肢 a の特徴ベ クトル, A は特徴の共起を含めた頻度を表す相関行列, b は
% 各ノードごとの報酬の総和を表すベクトル, θt は重みベク トル, pt,a は選択肢 a の評価値, α はバランスパラメータ, rt は報酬を表している. rt はプレイアウトにより与えるか, 学習データにより与えるものとする. LinUCB は 4 行目で 前回のプレイアウト結果を反映して重みベクトル θt を更 新する. 7 行目で重みベクトル, 特徴ベクトル, 相関行列を 用いて各ノードの評価値を計算し, 9 行目で評価値が最大 となるノードを選択する. 10 行目でプレイアウトを行い報 酬を受け取り, 11 行目, 12 行目で A と b の更新を行う.
% LinUCB は Algorithm 1 の 7 行目に示したように, 式 (2) により各ノードの評価値を求める. 式 (2) の第 1 項は各ノー ドの平均報酬を計算しており, 第 2 項で信頼度を計算して いる.
% ￼￼￼pt,a = θTt xt,a + α
% また, UCB で用いている評価値も, 平均報酬と信頼度の和 で計算される. つまり LinUCB と UCB は本質的に等しい 計算をしていることが分かる. また, LinUCB の第 2 項は データ数の増加により十分速く小さくなることが保証され ている [5]. 以上より, LinUCB は UCB と近い運用を行う ことができると考えられる.